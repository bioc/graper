{
    "collab_server" : "",
    "contents" : "---\ntitle: \"Using gprRR: Example with simulated data\"\nauthor: \"Britta Velten\"\ndate: \"`r Sys.Date()`\"\noutput:\n  BiocStyle::html_document:\n    toc: true\nvignette: >\n  %\\VignetteIndexEntry{Example_Simulation}\n  %\\VignetteEngine{knitr::rmarkdown}\n  %\\VignetteEncoding{UTF-8}\n---\n\n\n```{r, message=F}\n#library(grpRR)\nlibrary(GRridge)\nlibrary(ipflasso)\nlibrary(glmnet)\ndevtools::load_all(\"~/Documents/LassoVariants/multiviewHDR/grpRR/\")\nlibrary(ggplot2)\nlibrary(gridExtra)\nlibrary(dplyr)\nlibrary(randomForest)\nknitr::opts_chunk$set(fig.width = 15)\n```\n\n\n# Introduction\nThis vignette illustrates the use of the grpRR model on simulated data.\n\n#Simulate from the hierarchical model with known parameters\n```{r}\n\n```\n\n\n##No with-in group sparsity\n```{r}\nintercept<-0\nntotal<-500\nwhich4train<-1:100\nwhich4test<-101:ntotal\ntau<-10\n\nset.seed(Sys.time())\nrnd<-sample(1:1000000,1)\nrnd\np<-400\ndata<-simulate_grpLM(n=ntotal,p=p, beta_best=3, G=4, block_cor=0.3, blockSize=10, equiCor=0.1,\n                       SLinG=0.9, SLovG=0.5, model=\"linear\", diffFac=0.7, seed=rnd, sigma2=1/tau, family=\"gaussian\")\n# #ELB works with high correlations \n# data<-simulate_grpLM(n=ntotal,p=p, beta_best=3, G=4, block_cor=0.7, blockSize=10, equiCor=0.5,\n#                        SLinG=0, SLovG=0.5, model=\"linear\", diffFac=0.7, seed=rnd, sigma2=1/tau, family=\"gaussian\")\n# #ELB works with binary model\n# data$X[,1:200]<-matrix(rbinom(ntotal*10,1, 0.3), ncol = 200)\n# #works with highly misspecified model\n# data$y<-rbeta(ntotal,1,0.2)\n#plotit needs to trace parameters over iterations, not implemented yet\nAllFits<-RunMethods(Xtrain = scale(data$X[which4train,]), ytrain = data$y[which4train], \n                    annot = data$annot, max_iter = 3000,  intercept = T, \n                    trueintercept = intercept, beta0=data$beta0, plotit = F,  compareGRridge = T, \n                    standardize = T, include_nonfacQ = T, includeRF = F,freqELB = 100, verbose=T, th= 1e-5)\n#Checking convergence of ELB\nplot(AllFits$result$ELB_trace)\nplot(AllFits$resultSS$ELB_trace)\nplot(AllFits$resultFF$ELB_trace)\n\n#running times\nAllFits$result$runningTime\nAllFits$resultFF$runningTime\nAllFits$resultSS$runningTime\n\nout<-evalResult(AllFits, Xtest=data$X[which4test,], ytest=data$y[which4test], plotbeta=T)\n\n# #estimated posterior distributions of individual parameters\n# plotPosterior(AllFits$result, beta0=data$beta0, tau0=tau)\n```\n\nWithout intercept\n```{r}\nAllFits<-RunMethods(Xtrain = data$X[which4train,], ytrain = data$y[which4train], annot = data$annot, max_iter = 1000, \n           intercept = F, trueintercept = intercept, beta0=data$beta0, plotit = F, standardize = T)\nevalResult(AllFits, Xtest=data$X[which4test,], ytest=data$y[which4test], plotbeta = T)\n\n# #estimated posterior distributions of individual parameters\n# plotPosterior(AllFits$result, beta0=data$beta0, tau0=tau)\n```\n\n##Additional sparsity within informative groups\n```{r}\n#with in-group-sparsity\nset.seed(Sys.time())\nrnd<-sample(1:1000000,1)\nrnd\ndata<-simulate_grpLM(n=540,p=100, beta_best=3, G=10, block_cor=0, blockSize=10, equiCor=0,\n                       SLinG=0.5, SLovG=0.5, model=\"linear\", diffFac=0.7, seed=rnd, sigma2=0.1, family=\"gaussian\")\nAllFits<-RunMethods(Xtrain = data$X[which4train,], ytrain = data$y[which4train], annot = data$annot, max_iter = 1000, \n           intercept = T, trueintercept = intercept, beta0=data$beta0, plotit = F, standardize = T)\n#Checking convergence of ELB\nplot(AllFits$result$ELB_trace)\nplot(AllFits$resultFF$ELB_trace)\nplot(AllFits$resultSS$ELB_trace)\n\nevalResult(AllFits, Xtest=data$X[which4test,], ytest=data$y[which4test], plotbeta=T)\n\n#estimated posterior distributions of individual parameters\n# plotPosterior(AllFits$result, beta0=data$beta0, tau0=tau)\n\n```\n\n```{r}\n#with in-group-sparsity\nset.seed(Sys.time())\nrnd<-sample(1:1000000,1)\nrnd\ndata<-simulate_grpLM(n=540,p=100, beta_best=3, G=10, block_cor=0, blockSize=10, equiCor=0,\n                       SLinG=0.8, SLovG=0.5, model=\"linear\", diffFac=0.7, seed=rnd, sigma2=0.1, family=\"gaussian\")\nAllFits<-RunMethods(Xtrain = data$X[which4train,], ytrain = data$y[which4train], annot = data$annot, max_iter = 1000, \n           intercept = T, trueintercept = intercept, beta0=data$beta0, plotit = F, standardize = T)\n#Checking convergence of ELB\nplot(AllFits$result$ELB_trace)\nplot(AllFits$resultSS$ELB_trace)\n\nevalResult(AllFits, Xtest=data$X[which4test,], ytest=data$y[which4test], plotbeta=T)\n\n#estimated posterior distributions of individual parameters\n# plotPosterior(AllFits$result, beta0=data$beta0, tau0=tau)\n\nsave(list=ls(), file= paste(\"all_sim_p\",p,\"n\",ntotal,\"_170515.RData\", sep=\"\"))\n```\n\n\n###Evaluation for repeated number of simulations\nRepeat estiamtion over several simulation of testdata and evaluate perfromance in prediction and feature selection.\n\nNOTE: In some cases GRridge gives an error..., therefore only included optionally (compareRidge =F by default)\n\n####Dense Groups\n```{r}\nPredPerfromDF<-data.frame()\nPFDF<-data.frame()\nELB<-list()\nELB_FF<-list()\nELB_SS<-list()\n\ngamma_dense<-gamma_sparse<-pi_sparse<-data.frame()\nfor(simNo in 1:10){\nset.seed(Sys.time())\nrnd<-sample(1:1000000,1)\nrnd #seed for simulation of data\n\ndata<-simulate_grpLM(n=600,p=300, beta_best=5, G=6, block_cor=0.3, blockSize=10, equiCor=0.1,\n                       SLinG=0, SLovG=0.5, model=\"linear\", diffFac=0.7, seed=rnd, sigma2=0.1, family=\"gaussian\", onlypos=F)\nwhich4train<-1:100\nwhich4test<-101:600\n\n#test if an intercept is estimated correctly\nintercept<-0\ndata$y<-data$y+intercept\n\nAllFits<-RunMethods(Xtrain = data$X[which4train,], ytrain = data$y[which4train], annot = data$annot, max_iter = 1500, \n           intercept = T, trueintercept = intercept, beta0=data$beta0, plotit=F, standardize = T, includeRF = F, compareGRridge = F, freqELB = 1000)\n\n  ELB[[simNo]]<-AllFits$result$ELB_trace\n  ELB_FF[[simNo]]<-AllFits$resultFF$ELB_trace\n  ELB_SS[[simNo]]<-AllFits$resultSS$ELB_trace\n  \nEvalOut_current<-evalResult(AllFits, Xtest=data$X[which4test,], ytest=data$y[which4test], plotit = F)\n\n  PredPerfromDFcurrent<-cbind(EvalOut_current$EvalDF,  run =simNo, seed=rnd)\n  PredPerfromDF<-rbind(PredPerfromDF, PredPerfromDFcurrent)\n  \n  PFDFcurrent<-cbind(EvalOut_current$DFGroupPenalties,  run =simNo, seed=rnd)\n  PFDF<-rbind(PFDF, PFDFcurrent)\n  \ngamma_dense<-rbind(gamma_dense,as.numeric(AllFits$result$EW_gamma))\ngamma_sparse<-rbind(gamma_sparse,as.numeric(AllFits$resultSS$EW_gamma))\npi_sparse<-rbind(pi_sparse, as.numeric(AllFits$resultSS$EW_pi))\n}\n\npi_sparse<-colMeans(pi_sparse)\ngamma_sparse<-colMeans(gamma_sparse)\ngamma_dense<-colMeans(gamma_dense)\n\n\nggMSE<-ggplot(PredPerfromDF, aes(x=method, fill=method, y=MSE))+geom_boxplot()+\n      theme(axis.text.x = element_text(angle = 60, hjust = 1))\n\nEvalDF_sub<-filter(PredPerfromDF, method %in% c(\"beta_EN\", \"beta_lasso\",\"beta_estSS\", \"beta_estSScutoff\", \"beta_ridge\", \"beta_est\", \"beta_estFF\",\n                             \"beta_grplasso\", \"beta_true\", \"beta_zeromodel\"))\nggplot(EvalDF_sub, aes(x=method, fill=method, y=MSE))+geom_boxplot()+\n      theme(axis.text.x = element_text(angle = 60, hjust = 1))\n\n\nEvalDF_sub<-filter(PredPerfromDF, method %in% c(\"beta_lasso\",\"beta_ridge\", \"beta_est\", \"beta_estFF\", \"beta_zeromodel\"))\nggplot(EvalDF_sub, aes(x=method, fill=method, y=MSE))+geom_boxplot()+theme_set(theme_gray(base_size = 20)+ theme(axis.text.x = element_text(angle = 60, hjust = 1)) )\n\n\nPFDF_sub<-filter(PFDF, variable %in% c(\"gamma_dense\", \"sparsity_true\", \"gamma_dense_ff\"))\nggPF<-ggplot(PFDF, aes(x=group, fill=variable, y=value))+geom_boxplot()+\n      theme(axis.text.x = element_text(angle = 60, hjust = 1)) +ggtitle(paste(\"Penalty factors \"))+\n      facet_wrap(~variable, scales = \"free_y\")\nprint(ggPF)\n\nPFDF_sub<-filter(PFDF, variable!=\"beta0\")\nggPF<-ggplot(PFDF_sub, aes(x=group, fill=variable, y=value))+geom_boxplot()+theme_set(theme_gray(base_size = 20)+ theme(axis.text.x = element_text(angle = 60, hjust = 1)) ) +ggtitle(paste(\"Penalty factors \"))+\n      facet_wrap(~variable, scales = \"free_y\")\nprint(ggPF)\n\nPFDF_sub<-filter(PFDF, variable %in% c(\"gamma_sparse\", \"sparsity_true\", \"pi_sparse\"))\nggPF<-ggplot(PFDF_sub, aes(x=group, fill=variable, y=value))+geom_boxplot()+\n      theme(axis.text.x = element_text(angle = 60, hjust = 1)) +ggtitle(paste(\"Penalty factors \"))+\n      facet_wrap(~variable, scales = \"free_y\")\nprint(ggPF)\n\nggDiff<-ggplot(PredPerfromDF, aes(x=method, fill=method, y=L1DiffBeta))+geom_boxplot()+\n      theme(axis.text.x = element_text(angle = 60, hjust = 1))\nggIntercept<-ggplot(PredPerfromDF, aes(x=method, fill=method, y=InterceptDiff))+geom_boxplot()+\n      theme(axis.text.x = element_text(angle = 60, hjust = 1))\n\ngridExtra::grid.arrange(ggDiff,ggMSE,ggIntercept, ncol=2, nrow=2)\n\n\n# # average penalty and sparsity factors\n# par(mfrow=c(2,2))\n# barplot(gamma_dense, main=\"gamma in dense model (precision)\", names.arg = \"\")\n# barplot(gamma_sparse, main=\"gamma in SSmodel (precision) \", names.arg = \"\")\n# barplot(pi_sparse, main=\"pi in SSmodel (probability of being 'on'\", names.arg = \"\")\n```\n\n####Sparse Groups\nWithin group sparsity needs to be pretty high (0.8) for the spike and slab method to be beneficial.\n\n```{r}\nPredPerfromDF<-data.frame()\nPFDF<-data.frame()\nbetaDF<-data.frame()\ngamma_dense<-gamma_sparse<-pi_sparse<-data.frame()\n\nfor(simNo in 1:3){\nset.seed(Sys.time())\nrnd<-sample(1:1000000,1)\nrnd #seed for simulation of data\n\n# data<-simulate_grpLM(n=540,p=80, beta_best=3, G=8, block_cor=0.3, blockSize=10, equiCor=0.1,\n                       # SLinG=0.8, SLovG=0.5, model=\"linear\", diffFac=0.7, seed=rnd, sigma2=0.1, family=\"gaussian\", onlypos=F)\n\n\nG <- 5\npG <- 30\np <- G*pG\nannot <- rep(1:G, each=pG)\nn <- 540\ngamma<-c(0.05,10000,0.2,3000,0.1) #10,2.1,0.12,6.5, 10000)\ntau<-10\nbeta<-sapply(gamma[annot], function(prec) rnorm(1,0, 1/prec))\nX<-matrix(rnorm(pG*G*n), ncol=pG*G, nrow=n)\ny<-X%*%beta+rnorm(n,0,1/tau)\n\ndata$X <- X\ndata$y <- y\ndata$annot <- annot\ndata$beta0 <- beta\nwhich4train<-1:40\nwhich4test<-41:540\nintercept <- 0\n\n#test if an intercept is estimated correctly\nintercept<--20\ndata$y<-data$y+intercept\n\nAllFits<-RunMethods(Xtrain = data$X[which4train,], ytrain = data$y[which4train], annot = data$annot, max_iter = 3000, \n           intercept = T, trueintercept = intercept, beta0=data$beta0, plotit=F, standardize = T)\nEvalOut<-evalResult(AllFits, Xtest=data$X[which4test,], ytest=data$y[which4test], plotit = F)\n  \n  PredPerfromDFcurrent<-cbind(EvalOut$EvalDF,  run =simNo)\n  PredPerfromDF<-rbind(PredPerfromDF, PredPerfromDFcurrent)\n  \n  PFDFcurrent<-cbind(EvalOut$DFGroupPenalties,  run =simNo)\n  PFDF<-rbind(PFDF, PFDFcurrent)\n  \n  betaDFcurrent<-cbind(EvalOut$betaDF,  run =simNo)\n  betaDF<-rbind(betaDF, betaDFcurrent)\n}\n\npi_sparse<-colMeans(pi_sparse)\ngamma_sparse<-colMeans(gamma_sparse)\ngamma_dense<-colMeans(gamma_dense)\n\n# \n# ggMSE<-ggplot(EvalDF, aes(x=method, fill=method, y=MSE))+geom_boxplot()+\n#       theme(axis.text.x = element_text(angle = 60, hjust = 1))\n# ggDiff<-ggplot(EvalDF, aes(x=method, fill=method, y=L1DiffBeta))+geom_boxplot()+\n#       theme(axis.text.x = element_text(angle = 60, hjust = 1))\n# ggIntercept<-ggplot(EvalDF, aes(x=method, fill=method, y=InterceptDiff))+geom_boxplot()+\n#       theme(axis.text.x = element_text(angle = 60, hjust = 1))\n# \n# gridExtra::grid.arrange(ggDiff,ggMSE,ggIntercept, ncol=2, nrow=2)\n\n\nggMSE<-ggplot(filter(PredPerfromDF, method %in% c(\"beta_est\", \"beta_ridge\", \"beta_lasso\", \"beta_estFF\", \"beta_zeromodel\")), aes(x=method, fill=method, y=MSE))+geom_boxplot()+\n      theme(axis.text.x = element_text(angle = 60, hjust = 1))+ggtitle(paste(\"MSE\"))\nprint(ggMSE)\n\nggPF<-ggplot(PFDF, aes(x=group, fill=variable, y=value))+geom_boxplot()+\n      theme(axis.text.x = element_text(angle = 60, hjust = 1)) +ggtitle(paste(\"Penalty factors\"))+\n      facet_wrap(~variable, scales = \"free_y\")\nprint(ggPF)\n\nggbeta<-ggplot(betaDF, aes(x=FeatureNo, fill=group, y=value, group=FeatureNo))+\n          geom_bar(position = \"dodge\", stat = \"summary\", fun.y = \"mean\")+\n          theme(axis.text.x = element_text(angle = 60, hjust = 1)) +ggtitle(paste(\"Mean estimated coefficients\")) +\n          facet_wrap(~variable, scales = \"free_y\")\nprint(ggbeta)\n\n# # average penalty and sparsity factors\n# par(mfrow=c(2,2))\n# barplot(gamma_dense, main=\"gamma in dense model (precision)\", names.arg = \"\")\n# barplot(gamma_sparse, main=\"gamma in SSmodel (precision) \", names.arg = \"\")\n# barplot(pi_sparse, main=\"pi in SSmodel (probability of being 'on'\", names.arg = \"\")\n```\n\n#Simulate data according to the hierarchical model with fixed gamma, correctly specified model\n```{r}\nG <- 5\npG <- 30\np <- G*pG\nannot <- rep(1:G, each=pG)\nn <- 40\ngamma<-c(1,0.8,2,3,1/2) #10,2.1,0.12,6.5, 10000)\ntau<-10\nbeta<-sapply(gamma[annot], function(prec) rnorm(1,0, 1/prec))\nX<-matrix(rnorm(pG*G*n), ncol=pG*G, nrow=n)\ny<-X%*%beta+rnorm(n,0,1/tau)\n\n#fit model\nAllFits<-RunMethods(Xtrain = X, ytrain = as.vector(y), annot = annot, max_iter = 1500,\n                    intercept = F, trueintercept = 0, beta0=beta, plotit=F,\n                    standardize = T, freqELB = 300, verbose=T, compareGRridge = T)\n\n#estimated posterior distributions of individual parameters\nplotPosterior(AllFits$result, beta0=beta, tau0=tau, gamma0=gamma)\n\n#Checking convergence of ELB\nplot(AllFits$result$ELB_trace)\nplot(AllFits$resultSS$ELB_trace)\nplot(AllFits$resultFF$ELB_trace)\n\nbetaDF<-AllFits$DFresult[,grepl(\"beta\", colnames(AllFits$DFresult))]\ncols<-rainbow(ncol(betaDF))\n\nbarplot(t(as.matrix(betaDF)[41:60,]), beside=T, col=cols, main=\"Coefficients in highly informative groups\")\nlegend(\"bottomright\",colnames(betaDF),fill=cols)\n\nbarplot(t(as.matrix(betaDF)[(p-20):p,]), beside=T, col=cols, main=\"Coefficients in less informative groups\")\nlegend(\"bottomright\",colnames(betaDF),fill=cols)\n\n#prediction performance\nn<-200\nX<-matrix(rnorm(pG*G*n), ncol=pG*G, nrow=n)\ny<-X%*%beta+rnorm(n,0,1/tau)\nevalResult(AllFits, Xtest= X, ytest=y)\n\n```\n\n\n#More heterogeneity in groups, correctly specified model\n```{r}\nG<-10\npG<-20\np<-G*pG\nannot<-rep(1:G, each=pG)\nn<-90\ntau<-100\nbeta<-sapply(annot, function(var) rnorm(1,0,var^2))\nbarplot(beta)\n\nX<-matrix(rnorm(pG*G*n), ncol=pG*G, nrow=n)\ny<-X%*%beta+rnorm(n,0,1/tau)\n\n\n#fit model\nAllFits<-RunMethods(Xtrain = X, ytrain = as.vector(y), annot = annot, max_iter = 1000,\n                    intercept = F, trueintercept = 0, beta0=beta, plotit=F, standardize = T)\n\nbetaDF<-AllFits$DFresult[,grepl(\"beta\", colnames(AllFits$DFresult))]\ncols<-rainbow(ncol(betaDF))\n\nbarplot(t(as.matrix(betaDF)[1:20,]), beside=T, col=cols, main=\"Coefficients in less informative groups\")\nlegend(\"bottomright\",colnames(betaDF),fill=cols)\n\nbarplot(t(as.matrix(betaDF)[(p-20):p,]), beside=T, col=cols, main=\"Coefficients in highly informative groups\")\nlegend(\"bottomright\",colnames(betaDF),fill=cols)\n\n\n#prediction performance\nn<-200\nX<-matrix(rnorm(pG*G*n), ncol=pG*G, nrow=n)\ny<-X%*%beta+rnorm(n,0,1/tau)\nevalResult(AllFits, Xtest= X, ytest=y)\n```\n\n\n#More samples than features, correctly specified model\n```{r}\nG<-10\npG<-20\np<-G*pG\nannot<-rep(1:G, each=pG)\nn<-300\ntau<-100\nbeta<-sapply(annot, function(var) rnorm(1,0,var^2))\nbarplot(beta)\n\nX<-matrix(rnorm(pG*G*n), ncol=pG*G, nrow=n)\ny<-X%*%beta+rnorm(n,0,1/tau)\n\n#additional lm fit\nlmfit<-lm(y~X)\nbeta_lm<-lmfit$coefficients\n\n#fit model\nAllFits<-RunMethods(Xtrain = X, ytrain = as.vector(y), annot = annot, max_iter = 1000,\n                    intercept = T, trueintercept = 0, beta0=beta, plotit=F, standardize = T)\n\n\nbetaDF<-cbind(AllFits$DFresult[,grepl(\"beta\", colnames(AllFits$DFresult))], beta_lm=beta_lm)\ncols<-rainbow(ncol(betaDF))\n\nbarplot(t(as.matrix(betaDF)[1:20,]), beside=T, col=cols, main=\"Coefficients in less informative groups\")\nlegend(\"bottomright\",colnames(betaDF),fill=cols)\n\nbarplot(t(as.matrix(betaDF)[(p-20):p,]), beside=T, col=cols, main=\"Coefficients in less informative groups\")\nlegend(\"bottomright\",colnames(betaDF),fill=cols)\n\n\n#prediction performance\nn<-200\nX<-matrix(rnorm(pG*G*n), ncol=pG*G, nrow=n)\ny<-X%*%beta+rnorm(n,0,1/tau)\nevalResult(AllFits, Xtest= X, ytest=y)\nMSE_lm<-1/n*sum((y-cbind(1,X)%*%beta_lm)^2)\nMSE_lm\n```\n\n\n#Misspecified model\n```{r}\nG<-10\npG<-20\np<-G*pG\nannot<-rep(1:G, each=pG)\nn<-100\ntau<-100\nbeta<-sapply(annot, function(var) rnorm(1,0,var^2))\nbarplot(beta)\n\nX<-matrix(rnorm(pG*G*n,30), ncol=pG*G, nrow=n)\ny<-log(X)%*%beta+rnorm(n,0,1/tau)\n\n#fit model\nAllFits<-RunMethods(Xtrain = X, ytrain = as.vector(y), annot = annot, \n                    max_iter = 1000,intercept = T, trueintercept = 0, beta0=beta, plotit=F, standardize = T)\n\n\nbetaDF<-cbind(AllFits$DFresult[,grepl(\"beta\", colnames(AllFits$DFresult))])\ncols<-rainbow(ncol(betaDF))\n\nbarplot(t(as.matrix(betaDF)[2:20,]), beside=T, col=cols, main=\"Coefficients in less informative groups\")\nlegend(\"bottomright\",colnames(betaDF),fill=cols)\n\nbarplot(t(as.matrix(betaDF)[(p-20):p,]), beside=T, col=cols, main=\"Coefficients in less informative groups\")\nlegend(\"bottomright\",colnames(betaDF),fill=cols)\n\n\n#prediction performance\nn<-200\nX<-matrix(rnorm(pG*G*n,30), ncol=pG*G, nrow=n)\ny<-log(X)%*%beta+rnorm(n,0,1/tau)\nAllFits$beta0<-NULL\nevalResult(AllFits, Xtest= X, ytest=y)\n```\n\n#Real data with simulated response\nUsing methylation data from CLL data\n```{r}\ndata(\"CLLOmics\")\nMethViews<-CLLOmics[grepl(\"met\",names(CLLOmics))]\n\nntop<-200\n#only take top most variable genes and meth\nfilteredMethViews<-lapply(MethViews, function(dat){\n  var<-apply(dat,2, function(feat) var(feat, na.rm = T))\n  dat<-dat[,order(var, decreasing = T)[1:min(ntop, ncol(dat))]]\n  if(any(is.na(dat))){\n    #How many features are missing per patients?\n    if(any(rowSums(is.na(dat))/ncol(dat))<0.3) \n      warning(\"Patients included with less than 30% of features measured\")\n    #How many patiens are missing per feature?\n    PercMissing<-colSums(is.na(dat))/nrow(dat)\n    dat<-dat[,PercMissing<0.1]\n    dat<-apply(dat,2,ImputeByMean)\n  }\n  dat\n})\nsapply(filteredMethViews, dim)\nX<-do.call(cbind,filteredMethViews )\n\n#group annotations\nannotMeth<-rep(names(filteredMethViews), times=sapply(filteredMethViews, ncol))\n\n#set group weights\ngroupWeights<-rep(c(0,1,3,50,10,100), times=sapply(filteredMethViews, ncol))\nbeta<-sapply(groupWeights, function(var) rnorm(1,0,var^2))\nTrueBetaDF<-data.frame(feautreNo=1:length(beta),beta=beta, groupWeights=groupWeights, annot=annotMeth)\nggplot(TrueBetaDF, aes(x=feautreNo, y=beta, fill=annot))+geom_bar(stat=\"identity\")\n\n#simulate response\ntau<-100\ny<-X%*%beta+rnorm(nrow(X),0,1/tau)\n\n\n#test and training set\nset.seed(32423)\ntestsamples<-sample(1:nrow(X), 0.1*nrow(X))\nuse4test<-1:nrow(X) %in% testsamples\ntrainsamples<-(1:nrow(X))[!use4test]\n  #split in train and test data\n  ytrain<-y[ !use4test,,drop=F ]\n  ytest<-y[use4test,,drop=F]\n  Xtrain<-X[ !use4test,]\n  Xtest<-X[use4test,]\n  #remove features without variaton in training data\n  toKeep<-apply(Xtrain,2,var)>0\n  Xtrain<-Xtrain[,toKeep]\n  Xtest<-Xtest[,toKeep]\n  annotMeth<-annotMeth[toKeep]\n\n#fit model\nAllFits<-RunMethods(Xtrain = Xtrain, ytrain = as.vector(ytrain), annot = annotMeth, \n                    max_iter = 1000,intercept = T, trueintercept = 0, beta0=beta, plotit=F, standardize = T)\n\n\nbetaDF<-cbind(AllFits$DFresult[,grepl(\"beta\", colnames(AllFits$DFresult))])\ncols<-rainbow(ncol(betaDF))\n\nfor(group in unique(annotMeth)){\nbarplot(t(as.matrix(betaDF)[sample(which(annotMeth==group),20),]), beside=T, col=cols, main=paste(\"Some coefficients in\", group))\nlegend(\"bottomright\",colnames(betaDF),fill=cols)\n}\n\n\n#prediction performance\nevalResult(AllFits, Xtest= Xtest, ytest=ytest)\n```\n\n## Setting 1: add noise to feautres\nSame as above but add noise on feautres\n```{r}\ndata(\"CLLOmics\")\nMethViews<-CLLOmics[grepl(\"met\",names(CLLOmics))]\n\nntop<-100\n#only take top most variable genes and meth\nfilteredMethViews<-lapply(MethViews, function(dat){\n  var<-apply(dat,2, function(feat) var(feat, na.rm = T))\n  dat<-dat[,order(var, decreasing = T)[1:min(ntop, ncol(dat))]]\n  if(any(is.na(dat))){\n    #How many features are missing per patients?\n    if(any(rowSums(is.na(dat))/ncol(dat))<0.3) \n      warning(\"Patients included with less than 30% of features measured\")\n    #How many patiens are missing per feature?\n    PercMissing<-colSums(is.na(dat))/nrow(dat)\n    dat<-dat[,PercMissing<0.1]\n    dat<-apply(dat,2,ImputeByMean)\n  }\n  dat\n})\nsapply(filteredMethViews, dim)\nX<-do.call(cbind,filteredMethViews )\n\n#group annotations\nannotMeth<-rep(names(filteredMethViews), times=sapply(filteredMethViews, ncol))\n\n#set group weights\ngroupWeights<-rep(c(0,5,5,10,10,5), times=sapply(filteredMethViews, ncol))\nbeta<-sapply(groupWeights, function(var) rnorm(1,0,var^2))\nTrueBetaDF<-data.frame(feautreNo=1:length(beta),beta=beta, groupWeights=groupWeights, annot=annotMeth, noise=rep(c(0,2,0,2,0,2), times=sapply(filteredMethViews, ncol)))\nggplot(TrueBetaDF, aes(x=feautreNo, y=beta, fill=annot))+geom_bar(stat=\"identity\")\n\n#simulate response\ntau<-100\ny<-X%*%beta+rnorm(nrow(X),0,1/tau)\n\n#add noise on every second omic group\nannot_noise<-c(0,2,0,2,0,2)\nnames(annot_noise)<-unique(annotMeth)\nnoise<-sapply(unique(annotMeth), function(gr) matrix(rnorm(sum(annotMeth==gr)*nrow(X),0,annot_noise[gr]), nrow=nrow(X)))\nnoise<-do.call(cbind, noise)\nX<-X+noise\n  \n#test and training set\nset.seed(32423)\ntestsamples<-sample(1:nrow(X), 0.1*nrow(X))\nuse4test<-1:nrow(X) %in% testsamples\ntrainsamples<-(1:nrow(X))[!use4test]\n  #split in train and test data\n  ytrain<-y[ !use4test,,drop=F ]\n  ytest<-y[use4test,,drop=F]\n  Xtrain<-X[ !use4test,]\n  Xtest<-X[use4test,]\n  #remove features without variaton in training data\n  toKeep<-apply(Xtrain,2,var)>0\n  Xtrain<-Xtrain[,toKeep]\n  Xtest<-Xtest[,toKeep]\n  annotMeth<-annotMeth[toKeep]\n\n#fit model\nAllFits<-RunMethods(Xtrain = Xtrain, ytrain = as.vector(ytrain), annot = annotMeth, \n                    max_iter = 1000,intercept = T, trueintercept = 0, beta0=beta, plotit=F, standardize = T)\n\nTrueBetaDF$EW_gamma<-rep(AllFits$result$EW_gamma,times=sapply(filteredMethViews, ncol))\ng1<-ggplot(TrueBetaDF, aes(x=feautreNo, y=beta, color=noise))+geom_bar(stat=\"identity\")+facet_wrap(~annot)\ng2<-ggplot(TrueBetaDF, aes(x=feautreNo, y=EW_gamma, color=noise))+geom_bar(stat=\"identity\")+facet_wrap(~annot)\ngrid.arrange(g1,g2)\n\nbetaDF<-cbind(AllFits$DFresult[,grepl(\"beta\", colnames(AllFits$DFresult))])\ncols<-rainbow(ncol(betaDF))\n\nfor(group in unique(annotMeth)){\nbarplot(t(as.matrix(betaDF)[sample(which(annotMeth==group),20),]), beside=T, col=cols, main=paste(\"Some coefficients in\", group))\nlegend(\"bottomright\",colnames(betaDF),fill=cols)\n}\n\n\n#prediction performance\nevalResult(AllFits, Xtest= Xtest, ytest=ytest)\n```\n\n## Setting 2: sparse model\nSame as above but only some non-zero coefficeints per group\n```{r}\ndata(\"CLLOmics\")\nMethViews<-CLLOmics[grepl(\"met\",names(CLLOmics))]\n\nntop<-100\n#only take top most variable genes and meth\nfilteredMethViews<-lapply(MethViews, function(dat){\n  var<-apply(dat,2, function(feat) var(feat, na.rm = T))\n  dat<-dat[,order(var, decreasing = T)[1:min(ntop, ncol(dat))]]\n  if(any(is.na(dat))){\n    #How many features are missing per patients?\n    if(any(rowSums(is.na(dat))/ncol(dat))<0.3) \n      warning(\"Patients included with less than 30% of features measured\")\n    #How many patiens are missing per feature?\n    PercMissing<-colSums(is.na(dat))/nrow(dat)\n    dat<-dat[,PercMissing<0.1]\n    dat<-apply(dat,2,ImputeByMean)\n  }\n  dat\n})\nsapply(filteredMethViews, dim)\nX<-do.call(cbind,filteredMethViews )\n\n#group annotations\nannotMeth<-rep(names(filteredMethViews), times=sapply(filteredMethViews, ncol))\n\n#set group weights\ngroupWeights<-rep(c(0,5,5,10,10,5), times=sapply(filteredMethViews, ncol))\nbeta<-sapply(groupWeights, function(var) ifelse(rbinom(1,1,0.3)==0,rnorm(1,0,var^2),0))\nTrueBetaDF<-data.frame(feautreNo=1:length(beta),beta=beta, groupWeights=groupWeights, annot=annotMeth, noise=rep(c(0,2,0,2,0,2), times=sapply(filteredMethViews, ncol)))\nggplot(TrueBetaDF, aes(x=feautreNo, y=beta, fill=annot))+geom_bar(stat=\"identity\")\n\n#simulate response\ntau<-100\ny<-X%*%beta+rnorm(nrow(X),0,1/tau)\n\n#add noise on every second omic group\nannot_noise<-c(0,2,0,2,0,2)\nnames(annot_noise)<-unique(annotMeth)\nnoise<-sapply(unique(annotMeth), function(gr) matrix(rnorm(sum(annotMeth==gr)*nrow(X),0,annot_noise[gr]), nrow=nrow(X)))\nnoise<-do.call(cbind, noise)\nX<-X+noise\n  \n#test and training set\nset.seed(32423)\ntestsamples<-sample(1:nrow(X), 0.1*nrow(X))\nuse4test<-1:nrow(X) %in% testsamples\ntrainsamples<-(1:nrow(X))[!use4test]\n  #split in train and test data\n  ytrain<-y[ !use4test,,drop=F ]\n  ytest<-y[use4test,,drop=F]\n  Xtrain<-X[ !use4test,]\n  Xtest<-X[use4test,]\n  #remove features without variaton in training data\n  toKeep<-apply(Xtrain,2,var)>0\n  Xtrain<-Xtrain[,toKeep]\n  Xtest<-Xtest[,toKeep]\n  annotMeth<-annotMeth[toKeep]\n\n#fit model\nAllFits<-RunMethods(Xtrain = Xtrain, ytrain = as.vector(ytrain), annot = annotMeth, \n                    max_iter = 1000,intercept = T, trueintercept = 0, beta0=beta, plotit=F, standardize = T)\n\nTrueBetaDF$EW_gamma<-rep(AllFits$result$EW_gamma,times=sapply(filteredMethViews, ncol))\ng1<-ggplot(TrueBetaDF, aes(x=feautreNo, y=beta, color=noise))+geom_bar(stat=\"identity\")+facet_wrap(~annot)\ng2<-ggplot(TrueBetaDF, aes(x=feautreNo, y=EW_gamma, color=noise))+geom_bar(stat=\"identity\")+facet_wrap(~annot)\ngrid.arrange(g1,g2)\n\nbetaDF<-cbind(AllFits$DFresult[,grepl(\"beta\", colnames(AllFits$DFresult))])\ncols<-rainbow(ncol(betaDF))\n\nfor(group in unique(annotMeth)){\nbarplot(t(as.matrix(betaDF)[sample(which(annotMeth==group),20),]), beside=T, col=cols, main=paste(\"Some coefficients in\", group))\nlegend(\"bottomright\",colnames(betaDF),fill=cols)\n}\n\n\n#prediction performance\nevalResult(AllFits, Xtest= Xtest, ytest=ytest)\n```\n\n\n#Loud noisy and small informative\n```{r}\nG<-4\npG<-30\np<-G*pG\nannot<-rep(1:G, each=pG)\nn<-90\ntau<-100\nbeta<-sapply(annot, function(var) rnorm(1,0,ifelse(var%in%c(1,2),0,2)))\nbarplot(beta)\n#group 3 and 4 informative, 1 and 2 not\n\n#group 1 and 2 have high variance\nX<-cbind(matrix(rnorm(pG*G*n/2,0,1), nrow=n),matrix(rnorm(pG*G*n/2,0,100), nrow=n))\ny<-X%*%beta+rnorm(n,0,1/tau)\n\n\n#fit model\nAllFits<-RunMethods(Xtrain = X, ytrain = as.vector(y), annot = annot, max_iter = 1000,\n                    intercept = T, trueintercept = 0, beta0=beta, plotit=F, standardize = T)\n\nbetaDF<-AllFits$DFresult[,grepl(\"beta\", colnames(AllFits$DFresult))]\ncols<-rainbow(ncol(betaDF))\n\nbarplot(t(as.matrix(betaDF)[1:20,]), beside=T, col=cols, main=\"Coefficients in less informative groups\")\nlegend(\"bottomright\",colnames(betaDF),fill=cols)\n\nbarplot(t(as.matrix(betaDF)[(p-20):p,]), beside=T, col=cols, main=\"Coefficients in highly informative groups\")\nlegend(\"bottomright\",colnames(betaDF),fill=cols)\n\n\n#prediction performance\nn<-200\nX<-cbind(matrix(rnorm(pG*G*n/2,0,1), nrow=n),matrix(rnorm(pG*G*n/2,0,100), nrow=n))\ny<-X%*%beta+rnorm(n,0,1/tau)\nevalResult(AllFits, Xtest= X, ytest=y)\n```\n\n#Same coeffcients in groups, but very different scales\n```{r}\nG<-2\npG<-100\np<-G*pG\nannot<-rep(1:G, each=pG)\nn<-80\ntau<-100\nX<-cbind(matrix(rnorm(pG*G*n/2,0,1), nrow=n),matrix(rnorm(pG*G*n/2,0,100), nrow=n))\nbeta<-rep(0,p)\nbeta[c(1,2,3,4,5,101,102,103,104,105)]<-3\ny<-X%*%beta +rnorm(n,0,1/tau)\n\nAllFits<-RunMethods(Xtrain = X, ytrain = as.vector(y), annot = annot, max_iter = 1000,\n                    intercept = T, trueintercept = 0, beta0=beta, plotit=F, standardize = T)\n\nn<-200\nX<-cbind(matrix(rnorm(pG*G*n/2,0,1), nrow=n),matrix(rnorm(pG*G*n/2,0,100), nrow=n))\ny<-X%*%beta+rnorm(n,0,1/tau)\nevalResult(AllFits, Xtest= X, ytest=y)\n\n```\n\nWithout standardizing\n```{r}\nG<-2\npG<-100\np<-G*pG\nannot<-rep(1:G, each=pG)\nn<-80\ntau<-100\nX<-cbind(matrix(rnorm(pG*G*n/2,0,1), nrow=n),matrix(rnorm(pG*G*n/2,0,100), nrow=n))\nbeta<-rep(0,p)\nbeta[c(1,2,3,4,5,101,102,103,104,105)]<-3\ny<-X%*%beta +rnorm(n,0,1/tau)\n\nAllFits<-RunMethods(Xtrain = X, ytrain = as.vector(y), annot = annot, max_iter = 1000,\n                    intercept = T, trueintercept = 0, beta0=beta, plotit=F, standardize = F)\n\nn<-200\nX<-cbind(matrix(rnorm(pG*G*n/2,0,1), nrow=n),matrix(rnorm(pG*G*n/2,0,100), nrow=n))\ny<-X%*%beta+rnorm(n,0,1/tau)\nevalResult(AllFits, Xtest= X, ytest=y)\n\n```\n",
    "created" : 1495040652247.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1405996422",
    "id" : "BA415C94",
    "lastKnownWriteTime" : 1499169706,
    "last_content_update" : 1499169706,
    "path" : "~/Documents/LassoVariants/multiviewHDR/grpRR/vignettes/Example_Simulation.Rmd",
    "project_path" : "vignettes/Example_Simulation.Rmd",
    "properties" : {
    },
    "relative_order" : 1,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_markdown"
}